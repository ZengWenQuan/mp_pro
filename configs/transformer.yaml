# Model Configuration
model:
  name: transformer
  input_dim: 1
  d_model: 128
  nhead: 8
  num_layers: 3
  dim_feedforward: 512
  dropout_rate: 0.1
  batch_norm: true  # 添加BatchNorm配置
  output_dim: 3  # 预测三个特征：logg, feh, teff

# Data Configuration
data:
  train_dir: data/train  # 训练数据目录
  test_dir: data/test   # 测试数据目录
  # features_file: features_filtered_501features.csv  # 特征文件名
  features_file: features.csv  # 特征文件名
  labels_file: labels.csv     # 标签文件名
  data_size: 1000
  seq_len: 64
  feature_dim: 1
  val_split: 0.2
  test_split: 0.1
  num_workers: 4
  id_column: obsid
  labels:
    - logg  # Surface gravity
    - feh   # Metallicity
    - teff  # Effective temperature
  use_all_features: true  # 使用特征文件中的所有特征

# Training Configuration
training:
  device: 2  # Options: -1：cpu, 0,1,2,3：cuda
  batch_size: 32
  epochs: 100
  learning_rate: 0.0005  # Transformer通常使用较小的学习率
  weight_decay: 0.0001
  loss: mse  # Options: mse, mae, bce, ce
  optimizer: adam  # Options: adam, sgd, rmsprop
  scheduler: cosine  # Options: step, cosine, plateau, None
  early_stopping: -1  # -1 表示不启用早停机制，正整数表示早停的耐心值
  scheduler_params:
    t_max: 50  # For cosine scheduler
    warmup_steps: 10  # 学习率预热步数 